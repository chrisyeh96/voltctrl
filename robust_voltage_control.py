from __future__ import annotations

import io
from typing import Any

import cvxpy as cp
import numpy as np
from tqdm.auto import tqdm

from voltplot import VoltPlot


def robust_voltage_control(
        p: np.ndarray, qe: np.ndarray,
        v_lims: tuple[Any, Any], q_lims: tuple[Any, Any], v_nom: Any,
        X: np.ndarray, R: np.ndarray,
        Pv: np.ndarray, Pu: np.ndarray,
        eta: float | None, eps: float, v_sub: float, beta: float,
        sel: Any, pbar: tqdm | None = None,
        log: tqdm | io.TextIOBase | None = None,
        volt_plot: VoltPlot | None = None, volt_plot_update: int = 100,
        ) -> tuple[np.ndarray, np.ndarray, dict[str, list]]:
    """Runs robust voltage control.

    Args
    - p: np.array, shape [T, n], active power injection (MW)
    - qe: np.array, shape [T, n], exogenous reactive power injection (MVar)
    - v_lims: tuple (v_min, v_max), squared voltage magnitude limits (kV^2)
        - v_min, v_max could be floats, or np.arrays of shape [n]
    - q_lims: tuple (q_min, q_max), reactive power injection limits (MVar)
        - q_min, q_max could be floats, or np.arrays of shape [n]
    - v_nom: float or np.array of shape [n], desired nominal voltage
    - X: np.array, shape [n, n], line parameters for reactive power injection
    - R: np.array, shape [n, n], line parameters for active power injection
    - Pv: np.array, shape [n, n], quadratic (PSD) cost matrix for voltage
    - Pu: np.array, shape [n, n], quadratic (PSD) cost matrix for control
    - eta: float, noise bound (kV^2)
        - if None, assumes that eta is a model parameter that will be returned
          by `sel`
    - eps: float, robustness buffer (kV^2)
    - v_sub: float, fixed squared voltage magnitude at substation (kV^2)
    - sel: nested convex body chasing object (e.g., CBCProjection)
    - pbar: optional tqdm, progress bar
    - volt_plot: VoltPlot
    - volt_plot_update: int, time steps between updating volt_plot

    Returns
    - vs: np.array, shape [T, n]
    - qcs: np.array, shape [T, n]
    - dists: dict, keys ['t', 'true', 'prev'], values are lists
        - 't': list of int, time steps at which model updates occurred,
            i.e., X̂(t) != X̂(t-1). X̂(t) is generated by data up to and including
            v(t), q^c(t), u(t-1)
        - 'true': list of float, ||X̂-X||_△ after each model update
        - 'prev': list of float, ||X̂(t)-X̂(t-1)||_△ after each model update
    """
    assert p.shape == qe.shape
    T, n = qe.shape

    if log is None:
        log = tqdm()

    log.write(f'||X||_△ = {np_triangle_norm(X):.2f}')

    dists: dict[str, list] = {'t': [], 'true': [], 'prev': []}
    X̂_prev = None

    v_min, v_max = v_lims
    q_min, q_max = q_lims

    if eta is None:
        raise NotImplementedError  # we currently don't support learning eta
        # is_learning_eta = True
        # rho = eps / (2 + 2 * np.linalg.norm(np.ones(n) * (q_max-q_min), ord=2))
        # etahat_prev = None
    else:
        is_learning_eta = False
        rho = eps / (2 * np.linalg.norm(np.ones(n) * (q_max-q_min), ord=2))
    log.write(f'rho(eps={eps:.2f}) = {rho:.3f}')

    vs = sel.v  # shape [T, n], vs[t] denotes v(t)
    qcs = sel.q  # shape [T, n], qcs[t] denotes q^c(t)
    vpars = qe @ X + p @ R + v_sub  # shape [T, n], vpars[t] denotes vpar(t)
    assert np.array_equal(vs[0], vpars[0])

    # we need to use `u` as the variable instead of `qc_next` in order to
    # make the problem DPP-convex
    u = cp.Variable(n)
    slack = cp.Variable(nonneg=True)

    # parameters are placeholders for given values
    vt = cp.Parameter((n,))
    qct = cp.Parameter((n,))
    X̂ = cp.Parameter((n, n), PSD=True)
    # if eta is None:
    #     eta = cp.Parameter(nonneg=True)

    qc_next = qct + u
    v_next = vt + u @ X̂
    k = eta + rho * cp.norm(u, p=2)

    obj = cp.Minimize(cp.quad_form(v_next - v_nom, Pv)
                      + cp.quad_form(u, Pu)
                      + beta * slack**2)
    constraints = [
        q_min <= qc_next, qc_next <= q_max,
        v_min + k - slack <= v_next, v_next <= v_max - k + slack
    ]
    prob = cp.Problem(objective=obj, constraints=constraints)

    # if cp.Problem is DPP, then it can be compiled for speedup
    # - http://cvxpy.org/tutorial/advanced/index.html#disciplined-parametrized-programming
    assert prob.is_dcp(dpp=True)
    # log.write(f'Robust Oracle prob is DPP?: {prob.is_dcp(dpp=True)}')

    if pbar is not None:
        log.write('pbar present')
        pbar.reset(total=T-1)

    for t in range(T-1):  # t = 0, ..., T-2
        # fill in Parameters
        if is_learning_eta:
            raise NotImplementedError
            # X̂.value, eta.value = sel.select()
            # update_dists(dists, t, X̂.value, X̂_prev, X, eta.value, etahat_prev)
            # X̂_prev = np.array(X̂.value)  # save a copy
            # etahat_prev = float(eta.value)  # save a copy
        else:
            X̂.value = sel.select(t)
            update_dists(dists, t, X̂.value, X̂_prev, X, log=log)
            X̂_prev = np.array(X̂.value)  # save a copy
        qct.value = qcs[t]
        vt.value = vs[t]

        try:
            prob.solve(warm_start=True, solver=cp.MOSEK, mosek_params={'MSK_IPAR_NUM_THREADS': 1})
        except cp.SolverError:
            log.write(f't={t}. robust oracle: default solver failed. Trying cp.ECOS')
            prob.solve(solver=cp.ECOS)
        if prob.status != 'optimal':
            log.write(f't={t}. robust oracle: prob.status = {prob.status}')
            if 'infeasible' in prob.status:
                import pdb
                pdb.set_trace()

        qcs[t+1] = qc_next.value
        vs[t+1] = vpars[t+1] + qc_next.value @ X
        sel.add_obs(t+1)
        # log.write(f't = {t}, ||u||_1 = {np.linalg.norm(u.value, 1)}')

        if volt_plot is not None and (t+1) % volt_plot_update == 0:
            volt_plot.update(qcs=qcs[:t+2],
                             vs=np.sqrt(vs[:t+2]),
                             vpars=np.sqrt(vpars[:t+2]),
                             dists=(dists['t'], dists['true']))
            volt_plot.show(clear_display=False)

        if pbar is not None:
            pbar.update()
        if (t+1) % volt_plot_update == 0:
            log.write(f't={t}. robust oracle progress.')

    # update voltplot at the end of run
    if volt_plot is not None:
        volt_plot.update(qcs=qcs, vs=np.sqrt(vs), vpars=np.sqrt(vpars),
                         dists=(dists['t'], dists['true']))
        volt_plot.show(clear_display=False)

    return vs, qcs, dists


def np_triangle_norm(x: np.ndarray) -> float:
    """Computes ||X||_△"""
    return np.linalg.norm(np.triu(x), ord='fro')


def update_dists(dists: dict[str, list], t: int, Xhat: np.ndarray,
                 Xhat_prev: np.ndarray | None, X: np.ndarray,
                 log: tqdm | io.TextIOBase | None = None,
                 # etahat: float | None = None, etahat_prev: float | None = None
                 ) -> None:
    """Calculates ||X̂-X||_△ and ||X̂-X̂_prev||_△.

    Args
    - dists: dict, keys ['t', 'true', 'prev'], values are lists
        - 't': list of int, time steps at which model updates occurred,
            i.e., X̂(t) != X̂(t-1). X̂(t) is generated by data up to and including
            v(t), q^c(t), u(t-1)
        - 'true': list of float, ||X̂-X||_△ after each model update
        - 'prev': list of float, ||X̂(t)-X̂(t-1)||_△ after each model update
    - t: int, time step
    - Xhat: np.array, shape [n, n]
    - Xhat_prev: np.array, shape [n, n], or None
        - this should generally only be None on the 1st time step
    - X: np.array, shape [n, n]
    """
    # here, we rely on the fact that the CBCProjection returns the existing
    # variable X̂ if it doesn't need to move
    if Xhat_prev is None or not np.array_equal(Xhat, Xhat_prev):
        dist_true = np_triangle_norm(Xhat - X)
        msg = f't = {t:6d}, ||X̂-X||_△ = {dist_true:7.3f}'

        if Xhat_prev is None:
            dist_prev = 0.
        else:
            dist_prev = np_triangle_norm(Xhat - Xhat_prev)
            msg += f', ||X̂-X̂_prev||_△ = {dist_prev:5.3f}'
            # if etahat_prev is not None:
            #     msg += (f', etahat = {etahat:5.3f}, '
            #             f'|etahat - etahat_prev| = {etahat - etahat_prev:5.3f}')

        if log is None:
            log = tqdm
        log.write(msg)

        dists['t'].append(t)
        dists['true'].append(dist_true)
        dists['prev'].append(dist_prev)
